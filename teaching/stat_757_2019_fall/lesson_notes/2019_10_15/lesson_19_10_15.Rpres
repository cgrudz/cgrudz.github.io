<style>
.section .reveal .state-background {
   background: #ffffff;
}
.section .reveal h1,
.section .reveal h2,
.section .reveal p {
   color: black;
   margin-top: 50px;
   text-align: center;
}
</style>

Explanation
========================================================
date: 10/08/2019
autosize: true
incremental: true
width: 1920
height: 1080

<h2 style='color:black'>Instructions:</h2>
<p style='color:black'>Use the left and right arrow keys to navigate the presentation forward and backward respectively.  You can also use the arrows at the bottom right of the screen to navigate with a mouse.<br></p>

========================================================

<h2>Outline</h2>

* The following topics will be covered in this lecture:
  * Discussion of causality
  * The notion of statistical explanation
  *



========================================================

<h2>Explanation</h2>

* We have now explored the notion of a predictive model, but the notion of an explanatory model is more complicated philosophically.

* Sometimes explanation means causation by physical principles,

  * E.g., if we fit a linear model for a physical application, a paramater $\beta$ might be physical constant;
  
  * in particular, it could represent the ammount of energy lost due to friction in the moving parts of machine.
  
* However, sometimes explanation is just a description of the (conditional/ stastical) relationships between the variables. 

* Causal conclusions require stronger assumptions than those used for the predictive models that we have already discussed.

* Sometimes, we only wish to understand correlations, i.e., variables that (co)-vary together or asymmetrically...

========================================================

<h3>Correlation models</h3>

* ... but sometimes we can't read much into correlation:

<div style="float:left; width:75%">
<img style="width:100%", src="correlation_spider_bee.jpeg"/>
<b>Correlation: $80.5\%$ -- Courtesy of <a href="http://tylervigen.com/spurious-correlations" target="blank" alt="80.5 percent correlation between letters in winning word of Scripps National Spelling Bee and number of people killed by venomous spiders.">Tyler Vigen</a>, Creative Commons License</b>
</div>

========================================================

<h3> A simple meaning of explanation</h3>

* When we produce a linear model, we can consider the coefficients $\hat{\boldsymbol{\beta}}_i$ to provide an "explanation" of the effect of an explanatory variable on the response, e.g.,

```{r}
library("faraway")
lmod <- lm(Species ~ Area + Elevation + Nearest + Scruz + Adjacent, gala)
sumary(lmod)
```

* in this case, if we found a new island with elevation 100m higher (and with all other variables held constant) would appear to produce $\approx 32$ addtional species on a given island.


========================================================

<h3> A simple meaning of explanation -- continued</h3>


* However, if we try to perform the same analysis with respect to a different choice of model,

```{r}
sumary(lm(Species ~ Elevation, gala))
```

* we would have an explained response of about 20 additional species with a change of 100m of additional elevation.

* In general, the change in response variable in terms of an explanatory variable <b>needs to be qualified with respect to all variables in the model</b>.
  
* For example, 

  * "a unit increase in $\mathbf{X}_1$ with the other <b>(named)</b> predictors held constant will produce a change
of $\hat{\boldsymbol{\beta}}_1$ in the response $\mathbf{Y}$". 

* For the simple regression model with one variable explaning the response, the change in elevation is associated with a change in the other variables, not included in this simple model, but which in general may co-vary with this value. 

  * It was only in the special case where the predictors were not correlated that we saw the coefficient remains the same.
  
  * This explains why the two predictions in the ```Gala``` data are different.

* The regression coefficients thus give some explanation power, but it is <b>conditional</b> and lacks the notion of causality.

========================================================

<h2>Causality</h2>

* One common notion of causality is the following:
 
 * "<em>the causal effect of an action is the difference between the outcomes where the action was or was not taken</em>"
   
* In this understanding of causality we will typically consider prototypically an experiment with

  * a participant indexed by the letter $i$;
  
  * a measured quantity $\mathbf{Y}_i^T$ that may or may depend on the effect of some treatement;
  
  * $\mathbf{Y}_i^0$ will correspond to a control, where treatement <b>is not applied</b>;
  
  * $\mathbf{Y}_i^1$ will correspond to a test subject, where the treatment <b>is applied</b>; and
  
  * an effect $\delta_i \triangleq \mathbf{Y}_i^1 - \mathbf{Y}_i^0$.
  
* Usually, however, there will be no identical test subjects, and we can only observe one of $\mathbf{Y}^T_i$ for $T \in \{0, 1\}$.

* The outcome that we <em>cannot see</em> is called the <b>counterfactual</b>.

* In designed experiments, we may actually be able to control $T$, but for example with the Galapagos data, we cannot feasibly test a change in the elevation.

* Because many applications in data science and statistics will not (and often cannot) involve the best experimental design, we will focus our discussion on these cases.
  
  * We will treat the special case of designed experiments towards the end of the course.

========================================================

<h3> A concrete example</h3>

* In the 2008 Democratic primary election in New Hampshire, Hillary Clinton won despite the pre-election polls suggesting that Barack Obama would win.

<ul>
  <li>Two voting technologies were used in New Hampshire:</li>
  <ol>
    <li>paper ballots counted by hand; and</li>
    <li>optically scanned ballots, machine processed.</li>
  </ol>
<li>Controversially, on paper ballots Obama had more votes, whereas Clinton only won the primary in districts that used the machine counting.</li>
</ul>
```{r}
colSums(newhamp[newhamp$votesys =='D',2:3])
colSums(newhamp[newhamp$votesys =='H',2:3])
```

<li> Because the voting method shouldn't have any significant effect onthe outcome of the election, the integrity of the election was in question.</li>

========================================================

<h3> A concrete example -- continued</h3>

<ul>
  <li>In the following, we will try to model this to determine if the outcome would be surprising if it was due to random chance.</li>
  <li>Particularly, we want to understand how the significance of the explanatory variable, the method of voting, changes with respect to different choices of models.</li>

  <li><b>Note:</b></li>
  <ul>
    <li>Strictly speaking, this should be modelled by a <b>binomial distribution</b>;</li>
    <li>nonetheless, the normal can be a good approximation for the binomial given a large enough sample and probabilities not close to zero or one.</li>
    <li>A binomial variance is $np(1âˆ’p)$ for probability of success $p$, and sample size $n$. </li>
    <li>For both the votes for Clinton and Obama, the probability and sample sizes differ such that our assumption of constant variance is violated;</li>
    <ul>
      <li>with generalized least squares we can take this into account, but it doesn't make an appreciable difference in this case so we save this for later.</li>
    </ul>
    </ul>
  <li>We will start by fitting  a model with only the voting system as the explanatory variable...</li>
</ul>

========================================================
<h3> A concrete example -- continued</h3>

* We take a quick look at several of the predictors of interest:

```{r}
head(newhamp)
````


* The data includes the number of votes for Obama and Clinton, as well as total votes including other candidates.

* We have a variable ```votesys``` which is encoded as ```H``` or ```D``` for hand or digital vote counting respectively.

* There are also demographic variables, as well as proportion of votes cast for candidates in the 2004 presidential primary.

========================================================
<h3> A concrete example -- continued</h3>

* Here, we will re-code the ```votesys``` predictor as the ```trt```, treatment variable.

```{r}
newhamp$trt <- ifelse(newhamp$votesys == 'H',1,0)
lmodu <- lm(pObama ~ trt, newhamp)
sumary(lmodu)
```

* The model takes the form:

  $$\begin{align}
  y_i = \beta_0 + \beta_1T_i + \epsilon_i
  \end{align}$$
  
* where:

  * the response variable is the percentage of votes for Obama;
  
  * the base percentage of votes is represented by $\beta_0 \approx 35\%$;

  * when the voting system is by hand counting, $T_i = 1$ and the effect of a hand counting <em>in this model</em> is to add approximately $4\%$ to the vote total.


========================================================
<h3> A concrete example -- continued</h3>

```{r}
sumary(lmodu)
```
  
* We note that with the extremely small p-value for $\hat{\boldsymbol{\beta}}_1$, the effect of hand counting is statistically significant.

* In this case, we may conclude that Obama did receive significantly more votes in wards using hand counting, but this doesn't imply that <em>the voting method itself is the explanation</em>.

 * Among the issues in this conclusion, we risk the chance of an outright false positive for statistical significance.
 
 * Moreover, we haven't included how other possible predictors may covary with this value;
 
 * particularly, we need to determine if voting districts using hand counting versus digital technology were all highly correlated (vary closely) with another factor we have not included in our analysis.
 
 * Hand counting districts could be, for example, ones with significant demographic differences from the digital counting districts.

========================================================
<h2> Confounding variables</h2>

* We will suppose that this is the correct model, up to an additional variable we have left out of our analysis:

  $$\begin{align}
  y_i = \beta_0 + \beta^\ast_1T_i + \beta^\ast_2 Z_i + \epsilon_i 
  \end{align}$$
  
  * Where, as an ansatz, we take
  $$\begin{align}
  Z_i \triangleq \gamma_0 + \gamma_1 T_i + \epsilon^{\ast}_i 
  \end{align}$$
  
* We call the above $Z_i$ the <b>confounding variable</b>.

* By substition, we recover a new model

  $$\begin{align}
  y_i = \left(\beta_0 + \beta_2^\ast \gamma_0 \right) + \left(\beta^\ast_1 + \beta_2^\ast \gamma_1\right)T_i + \epsilon_i + \beta_2^\ast \epsilon^\ast_i
  \end{align}$$

* There are two scenarios where the effect of digital voting or hand counted voting agree between the original model and the model with the confounding variable:
<ol>
  <li> $\beta_2^\ast = 0$, so that $Z_i$ has no effect on the response; or </li>
  <li> $\gamma_1=0$, such that the effect of the treatement (hand or digital voting) has no effect on $Z_i$, the confounding variable.</li>
</ol>

* In any other case, our original model excluding $Z$ will be biased in its estimation of the effect of digital versus hand counting.

* In a designed experiement, $\gamma_1=0$ by randomization of the populations to which the control or the treatment is applied, but in this case we cannot assume this.

========================================================
### Confounding variables -- continued

* We wish thus to determine if there is a possible effect of a confounding variable in the model.

* In particular, we will consider the proportion of votes given to Howard Dean, the Democratic presidential candidate in 2004 as an explanatory variable on the response.

* We construct the revised model, including the ansatz in the R language,

  $$\begin{align}
  y_i = \left(\beta_0 + \beta_2^\ast \gamma_0 \right) + \left(\beta^\ast_1 + \beta_2^\ast \gamma_1\right)T_i + \epsilon_i + \beta_2^\ast \epsilon^\ast_i
  \end{align}$$
  

```{r}
lmodz <- lm(pObama ~ trt + Dean , newhamp)
```

========================================================
### Confounding variables -- continued

* Here, we study the model output:  
  
```{r}
sumary(lmodz)
```

* Things we thus note immediately are:
<ol>
  <li> the percentage of votes that went to Howard Dean in 2004 has a positive effect in this model, that dramatically counter-balances the effect of the counting method;</li>
  <li> the counting method in this model is no longer statistically significant, where the p-value is on the order of $54\%$. </li>
  <ul>
    <li>That is, under the null hypothesis, leaving out the counting method as an explanatory variable, we would expect to see such a t-test value $\approx 54\%$ of the time.
  <li>Therefore, the effect of the counting  method in this model (with the model conditioned on the Dean variable) is quite feasibly due to random chance.</li>
  </ul>
  <li>On the other hand, dropping the Dean variable out of the model seems like a bad choice; </li>
  <ul>
    <li>under the null hypothesis, leaving out Dean, the p-value for the t-test is on the order zero.</li>
  </ul>
</ol>

========================================================
### Testing the ansatz


* Recall the ansatz,
 
  $$\begin{align}
  Z_i \triangleq \gamma_0 + \gamma_1 T_i + \epsilon^{\ast}_i 
  \end{align}$$

* If we try to fit such a model, we see that

```{r}
sumary(lm(Dean ~ trt, newhamp))
```

* This says, we have found a statistically significant, linear relationship between the Dean variable $Z_i$ and the treatment (hand or digital counting) with the adjustment term $\gamma_1$.

  * This corroborates the ansatz we have proposed.

* It appears that there is an active confounding variable, but we will need additional analysis to make conclusions...

========================================================
### The analogy of the treatment

* Suppose we wish to follow the analogy of the clinical trial again, 

  * we might have individuals who differ in gender, age, health conditions, and other factors that can affect the outcome of the treatment;

  * we want to have individuals with equal (or extremely similar) traits balanced between the control and treatment populations to ensure that the traits of either group don't bias the results.

  * Knowing that there is some effect of a confounding variable in this analysis, we should specifically try to balance the effect of the confounding variable in both the control and treatment populations;
  
  * matching certain participants based on their relationship to the confouding variable, we will randomly select individuals from the matched groups as either a control or a treatment case.

* For the primary data, we will perform a similar procedure to match voting districts based on similar <em>proportions of votes going to Dean in 2004</em>, in order to evaluate the effect of the treatment, i.e., machine or hand counting of votes.

* Because this is observed data, we can't randomly assign the treament or control to these matched populations, but we will try to emulate the process.

========================================================
## Matching cases


* Dean is a continuous variable (precentage of district that voted for Dean) so we set a threshold for which pairs of districts are defined as "matches".

* The GenMatch is a (stochastic) selection algorithm based on genetic principles --- by random initialization and selection, it goes through iterations to find a "best fit".

  * As many matches are made as possible in a first iteration, from which a mutation to the selection is given;
  
  * if the number of matches increases from perturbing the selection, this is accepted as an "evolved solution" to the matching process.
  
* This continues until a certain number of attempts are reached, or a certain number of matches are created in an iteration.

* Because this is a random algorithm, we set a seed value so that we can reproduce the matching result in future attempts.

```{r cache=TRUE, results='hide'}
library("Matching")
set.seed(123)
mm <- GenMatch(newhamp$trt, newhamp$Dean, ties=FALSE, caliper=0.05, pop.size=1000)
```


========================================================
### Matching cases -- continued


* We print some of the matches:

```{r}
head(mm$matches[,1:2])
```

* and note the first case of the matches, where the proportion of votes is quite similar:

```{r}
newhamp[c(4,218),c('Dean','pObama','trt')]
```

========================================================
### Matching cases -- continued

<div style="float:left; width:50%">
<img style="width:100%", src="matching_plot.png" alt="Plot of matched pairs over the confounding variable Dean, and their differences in the response."/>
<p style="text-align:center">Courtesy of: Faraway, J. Linear Models with R. 2nd Edition</p>
</div>

<div style="float:left; width:50%">
<ul>
  <li> In the left plot, we show the matched pairs --- hand voting wards are shown as
triangles and digital voting wards as circles. 
  <ul>
    <li>These are matched based on similar values for the ```Dean``` variable in the horizontal axis, with the response value ```pObama``` in the vertical axis.</li>
  </ul>
<li>Matched pairs are linked by a line. In the right plot, we show the matched pair differences in the observed response value.</li>
</ul>
</div>

<div style="width:100%; float:left">
<ul>
 <li> We have now set up the close analog to the clinical experiment, with a control and treatment population of similar characteristics with respect to the confounding variable.</li>
 <li> We note that some districts go un-matched because the algorithm (after repeated attempts) couldn't find a maximal set of matches that could fit them in a pair with a similar treatment or control analogue based on our matching criterion.</li>
</ul>
</div>



========================================================
### Matching cases -- continued

<div style="float:left; width:50%">
<img style="width:100%", src="matching_plot.png" alt="Plot of matched pairs over the confounding variable Dean, and their differences in the response."/>
<p style="text-align:center">Courtesy of: Faraway, J. Linear Models with R. 2nd Edition</p>
</div>

<div style="float:left; width:50%">
<ul>
  <li> In the right plot, the matched pair differences gives us some idea of the effect of the "treatment" of hand counting votes.</li>
  <ul>
    <li> That is, let each pair be indexed by a number $i$ that identifies the pair;</li>
    <li> $T\in\{0, 1\}$ describes whether the district had hand counting ($T=1$) or digital counting ($T=0$);</li>
    <li> then, we denote $Y^T_i$ to be the observed percentage of votes for Obama in the 2008 primary election.
  </ul>
</ul>
</div>

<div style="width:100%; float:left">
<ul>
 <li> The differences in the treatment and control populations (the effect based on the cause),
 $$\begin{align}
 \delta_i = Y_i^1 - Y_i^0,
 \end{align}$$
 is thus represented by the differences in the right plot.</li>
 <li>Recall, $Y_i^T$ is assumed to be a random variable that is conditioned on the event of the treatment application or not.</li>
 <ul>
  <li>Therefore, $\delta_i$ is also a random variable</li>
 </ul>
 <li> We want to understand the random process represented by $\delta_i$.</li>
 <li> In particular, if the treatment doesn't introduce bias on the outcome of the vote, we should expect
 $$\begin{align}
 \mathbb{E}[\delta] = 0
 \end{align}$$</li>
</ul>
</div>

========================================================
### Testing for unbiased treatment

<ul>
<li>Suppose that we assume $\epsilon_i \sim N(0, \sigma^2)$ for every $i$;</li>
 <ul>
  <li><b>Q:</b> what way can we test that $\mathbb{E}\left[\delta\right] =0$?</li>
 </ul>
  <li><b>A:</b> we can perform this with the student t-test.</li>
  <li>Assuming:</li> 
  <ol>
    <li>Gaussiantiy of the errors $\epsilon$;</li>
    <li>independent cases; and</li>
    <li>finite constant variance of the errors across all cases,</li>
  </ol>
  <li>we can say $\delta_i$ are Gaussian random variables, independently and identically distriubted with unknown true mean and standard deviation.</li>
  <li><b>Exercise (2 minutes):</b> supposing that the unknown variance is $\sigma^2$, use the above assumptions to derive the variance of the $\delta_i$.</li>
  <li><b>Solution:</b> note that the random component of $\delta_i$ can be written $\epsilon_i^1 - \epsilon_i^0$, where these are uncorrelated Gaussian random variables, each with variance $\sigma^2$.</li>
  <li>Therefore,
  $$\begin{align}
  var(\delta_i) &= \mathbb{E}\left[ \left(\epsilon_i^1 - \epsilon_i^0\right)^2\right] \\
  &= \mathbb{E}\left[ \left(\epsilon_i^1\right)^2 - 2\epsilon_i^1 \epsilon_i^0 + \left(\epsilon_i^0\right)^2\right] \\
  &= 2 \sigma^2
  \end{align}$$
  due to uncorrelated errors and the constant variance.</li>
<li>Therefore, the t-test for a sample of iid random Gaussian variables appropriate.</li>
</ul>

========================================================
### Testing for unbiased treatment -- continued

* We will determine the significance of the alternative hypothesis that

  $$\begin{align}
  H_1: \mathbb{E}[\delta] \neq 0,
  \end{align}$$
  given the sample based mean and variance.

* The null hypothesis is,
  
  $$\begin{align}
  H_0: \delta \sim N(0, 2\sigma^2).
  \end{align}$$
  
* We construct the vector of differences and compute the t-test below:
  
```{r}
pdiff <- newhamp$pObama[mm$matches[,1]] - newhamp$pObama[mm$matches[,2]]
t.test(pdiff)
```

========================================================
### Testing for unbiased treatment -- continued

```{r}
t.test(pdiff)
```

* We note that we fail to reject the null hypothesis, i.e., it is plausible that the difference in the treatment is mean zero.

* While this p-value is close to the threshold $\alpha=5\%$, we note qualitatively from the $95\%$ confidence interval that,

  * across the matched cases for similar percentage votes in 2004 for Dean,
  
  * the effect of the treatment (hand counting) actually is skewed negative, contrary to the original concern of malfeasance.
  
* Across matched districts, the case for the vote counting method being the deciding factor in the election is losing strength. 

========================================================
### Testing for unbiased treatment -- continued

<div style="float:left; width:50%">
<img style="width:100%", src="matching_plot.png" alt="Plot of matched pairs over the confounding variable Dean, and their differences in the response."/>
<p style="text-align:center">Courtesy of: Faraway, J. Linear Models with R. 2nd Edition</p>
</div>

<div style="float:left; width:50%">
<ul>
  <li> By inspection, this corroborates the observation that the differences $\delta_i$ don't favor positive or negative impact on the percentage vote for Obama in the primaries.</li>
  <li> The data <em>appears sufficiently Gaussian</em>, that the assumptions of this test <em>seem</em> to be satisfied.</li>
  <ul>
    <li>However, we must acknowledge that we made a Gaussian approximation of the binomial distribution, and constant variance when the variances should probably be non-constant.</li>
    <li> We will return to these points, and how to test for Gaussianity and non-constant variances later in the course.</li>
  </ul>
</ul>
</div>

========================================================
## A summary of the results

<ul>
  <li>With this analysis we have established the following:
  <ol>
    <li>There is a statistically significant relationship between the districts where Obama held a majority in 2008 and those that used hand counted ballots.</li>
    <li> However, in the presence of the popularity of Dean in 2004 as an explanatory variable, the counting method didn't show significance;</li>
    <ul>
      <li>the ansatz that there is a linear relationship between the Dean 2004 percentage and the districts with hand counting held with significance.</li> 
    </ul>
    <li> Therefore, we are inclined to favor Dean as a <b>confounding variable</b> in the analysis.</li> 
  </ol>
</ul>


========================================================
### A summary of the results -- continued


* In order to account for the confounding variable, we emulate the system of designed experiments with <em>balanced treatment and control groups</em>.

* Using a (random) selection algorithm we try to enforced balanced populations with respect to the confounding variable:
<ol>
  <li>  We specify a small threshold for a match;
  <li> the algorithm searches for districts that have comparable values of the confounding variable Dean, within the threshold;</li>
  <li> a match is set if one case used digital and one case used hand counting, representing the control and treament groups respectively;</li>
  <li> the algorithm then iteratively searches for as many matches as possible.</li>
</ol>

* By creating balanced populations with respect to the confounding variable, we can refine our analsis and determine if the treatment, <em>hand counted votes</em> had a statistically significant effect accounting for the stronger predictor.

* We perform a hypothesis test to see if the treatment bias away from zero on the response (percent vote Obama 2008).

* According to the t-test, we cannot reject the null hypothesis, that difference of the percent vote for Obama in the treatment and control groups is zero on average.

* In the following, we will visualize this process along with the difference between the two approaches.

========================================================
### A visual analysis

<div style="float:left; width:50%">
<img style="width:100%", src="lin_mod_plot.png" alt="Plot of matched pairs over the confounding variable Dean, and the regression functions including only the treatement, and/or including the confounding variable."/>
<p style="text-align:center">Courtesy of: Faraway, J. Linear Models with R. 2nd Edition</p>
</div>

<div style="float:left; width:50%">
<ul>
  <li> On the left we plot the mean of the response (percentage of 2008 primary votes to Obama), modeled as a response of:</li>
  <ol>
    <li> the method of vote counting (hand or digital); and</li>
    <li>the popularity of Dean in 2004. </li>
  </ol>
  <li> Solid (respectively dashed) lines corresponds to digital (respectively hand) counted votes;</li>
    <li> horizontal lines are irrespective of the confounding variable (Dean), and the models are fit only as a response of the voting method. </li>
<ul>
</div>

<div style="float:left; width:100%">
<ul>
  <li> Lines with positve slopes are fitted with Dean as an explanatory variable.</li>
  <li> Matched pairs (control/ treatment) are represented by (circles/ triangles) and connected by grey lines.</li>
  <li> In expected value (or on average) the difference between hand vote counting and digital vote counting is represented by the difference of the two sloped lines.</li>
  <li> The matched pairs can be seen as local variation around the mean differences.</li>
  <li> If we average all of the pairwise differences, we can likewise estimate the difference of mean responses by the mean of the differences.</li>
</ul>
</div>

========================================================
### A visual analysis

<div style="float:left; width:50%">
<img style="width:100%", src="lin_mod_plot.png" alt="Plot of matched pairs over the confounding variable Dean, and the regression functions including only the treatement, and/or including the confounding variable."/>
<p style="text-align:center">Courtesy of: Faraway, J. Linear Models with R. 2nd Edition</p>
</div>

<div style="float:left; width:50%">
<ul>
<li>In our original analysis, we found that the treatment was a significant explanatory variable.</li>
<li>However, this variable was found to have a statistically significant linear relationship with the <b>covariate</b> ```Dean```.</li>
<li> In this case, we find that both:</li>
<ol>
  <li> matching samples to produce balanced control and treatment groups between populations, based on the covariate; and</li>
  <li> including the covariate in the model itself</li>
</ol>
  <li>in this case these actually estimate the same phenomon.</li>
</ul>
</div>

========================================================
### Adjusting for the covariate


* Both techniques of adjusting for possible covariates are useful for analysis. 
   * Including the confounding variable in model is known as "controlling for the covariate".
   
   * This has the advantage that it extends well to multiple explanatory variables, where we define the new model in terms of additional predictors.
   
   * The disadvantage is that we must specify the form for the model itself.
   
* On the other hand, matching doesn't require us to specify an actual form for the relationship.

   * The weakness of this approach is that there has to be a sufficient number of matching pairs to form meaningful analysis over the control and treatment groups.
   
* Both methods coincide in this case because there is sufficient balance between the control and treatment group proportionally to the whole population to make meaningful conclusions.

* When there isn't much overlap, controlling for the covariate can still provide useful analysis but we have to be concious of extrapolation issues and uncertainty.

========================================================

<h2> Notes on explanation</h2>

*  In general, there are limits to the conclusions we can draw statistically from observational data.

*  Sir Bradford Hill, a figure in establishing the <em>causal link</em> between smoking and lung cancer made several reccomendations for how to study a causal link:
<ol>
  <li>Study the practical strength of the effect on response. This is not neccessarily in terms of high correlation or a small p-value but that the impact o $\hat{\beta}_i$ is large in the scale of the response.  If there is a large practical effect on the response variable, it is unlikely that another (un-modeled) variable would have a counter-active effect.</li>
  <li> Study the consistency of the results.  If smokers over many possible confounding variables all tend to get lung cancer, then the evidence is stronger.  Independent replication of results is an important link to causality.</li>
  <li> Consider the specificity of the causual factor.  If a particular lung disease is only prevalent in workers in a particular industry and those workers do not suffer from other problems any more than other industrial workers, then the case is stronger.</li>
  <li> Study the temporality to establish cause and effect.  You want to determine whether X causes Y or Y causes X, where there are many possible variables.</li>
  <li> Consider if the results corroborate other substantial evidence.  Determine the overal plausibility within existing understanding.</li>
</ol>

========================================================

## Diagnostics

<ul> 
  <li> Our analysis and methodology for:</li>

  <ol>
    <li> fitting a linear model; </li>
    <li> forecasting predictions from a linear model; and</li>
    <li> explaning the relationships between variables in a linear model</li>
  </ol>
</ul>
* all rely on several assumptions, e.g., the conditions for the Gauss Markov theorem.

* Methods for checking and validating these assumptions are known as <b>diagnostics</b>.

* Typically, we will start with one model as a best first guess.

* Performing diagnostics will reveal issues in the  model, and suggest ways for improvement.

* Building a model is thus usually an interactive, iterative process, where we will create and perform diagnostics over a succession of models.

========================================================

<h3>Constructing a regression model -- an iterative process</h3>
 
 
<div style="float:left; width:30%">
<img style="width:100%", src="flow_chart_a.png" alt="Flow chart from start of the regression analysis, to exploratory data analysis, to developing one or more possible models."/><p style="text-align:center"> Courtesy of: Kutner, M. et al. Applied Linear Statistical Models 5th Edition</p>
</div>
<div style="float:left; width:70%">
<ul>
  <li>Regression analysis is thus an iterative process, which typically follows the flow on the left.</li>
  <li>We must clean the data and perform exploratory analysis to determine relationships between the response, possible predictors, and the between the predictors themselves.</li>
  <li>This exploratory analysis helps us to develop one or more possible regression models for the study.</li>
</ul>
</div>


========================================================

<h3>Constructing a regression model -- an iterative process</h3>
 
 
<div style="float:left; width:50%">
<img style="width:100%", src="flow_chart_b.png" alt="Flow chart from developing one or more possible models, iterating if the models aren't appropriate for the data at hand, then identifying the most suitable model and making inferences."/><p style="text-align:center"> Courtesy of: Kutner, M. et al. Applied Linear Statistical Models 5th Edition</p>
</div>
<div style="float:left; width:50%">
<ul>
  <li> From the point of the last diagram, we can take our tenative models and evaluate if they are suitable for the problem and data.</li>
  <li> If not, we revise and repeat.</li>
  <li> If so, we compare the competing models for which one is most robust in our analysis --- particularly, if the model assumptions are well satisfied.</li>
  <li> If we are secure about the robustness of the model, having tested it in various ways, we can make inferences based on the model, such as predictions of future observations.</li>
  <ul>
    <li>Note, even when we feel quite confident in the model, it is key to <b>qualify our inferences by the uncertainty of the model</b>, e.g., providing confidence intervals.</li> 
  </ul>
  <li> The first part of this course has been focused on the situation in which assumptions are well satisfied and there exists a good linear signal in the data.</li>
</ul>
</div>


========================================================

### Diagnostics -- continued

<ul> 
  <li> In the rest of the class, we will consider 3 categories of potential issues with the model:</li>
  <ol>
    <li> Issues with the error/ variation.  Particularly, we have assumed that $\boldsymbol{\epsilon}\sim N(0, \sigma^2 \mathbf{I})$ such that the errors are normally distributed, independent and of constant variance.</li>
    <li> Issues with the systematic part of the model.  Particularly, we have assumed that there is an actual signal in the data of the form
    $$\begin{align}
    \mathbb{E}[\mathbf{Y}] = \mathbf{X} \boldsymbol{\beta},
    \end{align}$$
    which may not be valid.</li>
    <li> Issues with unusual observations.  Some of the observations may not fit the model, and they might change the choice and the fit of the model</li>
  </ol>
  <li>We will begin to study the methods of diagnostics and remediation in the next session.</li>
</ul>


